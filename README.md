This Python script is designed for analyzing a dataset of news articles to classify them as real or fake using machine learning techniques. It begins by importing necessary libraries such as NumPy, pandas, NLTK for natural language processing, and scikit-learn for machine learning tasks. The dataset, loaded from a CSV file, contains information like author, title, and label indicating whether the news is real (0) or fake (1). Initial data exploration includes checking for null values, which are then filled with empty strings for consistency in processing. The script preprocesses the textual data by combining author and title into a unified content field and applies text normalization techniques such as stemming to reduce words to their base forms and remove stopwords using NLTK's corpus. After preprocessing, the textual content is vectorized using TF-IDF (Term Frequency-Inverse Document Frequency) vectorization, which transforms the text into numerical features suitable for machine learning algorithms. The dataset is split into training and testing sets using a stratified approach to preserve the proportion of real and fake news samples in both sets. Several classifiers are implemented and evaluated: Logistic Regression, RandomForest, Decision Tree, and Gradient Boosting Classifier. Each model is trained on the training set and evaluated for accuracy on the test set, with results printed to the console. The script concludes by demonstrating the model's predictive capability on a sample test instance, showing whether the predicted news label corresponds to real or fake news based on the trained models. This script provides a comprehensive framework for analyzing news authenticity using machine learning, suitable for researchers, developers, or enthusiasts interested in text classification and natural language processing applications.
